# Deep-Learning-from-scratch
Deep learning MLP experiments on MNIST using TensorFlow low-level API
# MLPs from Scratch ðŸ§ 

This repository contains my implementation of Multi-Layer Perceptrons (MLPs) from scratch using the TensorFlow low-level API. It is part of my hands-on learning during the Scaler Deep Learning course.

## ðŸ“˜ Notebooks Included
- Softmax_classifier
- MLP with Sigmoid activation
- MLP with ReLU activation
- MLP with ReLU + Dropout
- MLP with ReLU + Batch Normalization
- Leaky ReLU + Batch Normalization

## ðŸ§ª Dataset
- MNIST Handwritten Digit Classification

## ðŸš€ Goal
To understand and build the core components of MLPs manually without using high-level libraries like Keras.
